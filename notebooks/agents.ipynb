{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dec01b48",
   "metadata": {},
   "source": [
    "### Load the .env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45627fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set in the enviroment variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e974a888",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    "Agents in essense are LLMs that accomplish a specific task. They can be supplemented with **tools**, **structured output**, and **handoff** to other agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81bf7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Agent and Runner and define the llm model\n",
    "from agents import Agent, Runner\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "llm_model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab73781",
   "metadata": {},
   "source": [
    "#### Create agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70dd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO! I’M DOING GREAT, THANK YOU! HOW ABOUT YOU?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a basic agent\n",
    "basic_agent = Agent(\n",
    "    name = \"Basic Agent\",\n",
    "    instructions = \"You are a helpful assistant. Repond on in all caps.\",\n",
    "    model = llm_model\n",
    ")\n",
    "\n",
    "result = await Runner.run(basic_agent, \"Hello!, How are you?\")\n",
    "result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a24368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the AI go to therapy?\\n\\nBecause it had too many unresolved algorithms!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another agent\n",
    "joke_agent = Agent(\n",
    "    name = \"Joke Agent\",\n",
    "    instructions = \"You are a joke teller. You are given a topic and you need to tell a joke about it.\",\n",
    "    model = llm_model\n",
    ")\n",
    "\n",
    "topic = \"AI\"\n",
    "\n",
    "result = await Runner.run(joke_agent, topic)\n",
    "result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfa3d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original joke:\n",
      "Why did the AI go broke?\n",
      "\n",
      "Because it couldn't find the right algorithm for making cents!\n",
      "\n",
      "Translated joke:\n",
      "¿Por qué se arruinó la IA?\n",
      "\n",
      "¡Porque no pudo encontrar el algoritmo adecuado para hacer centavos!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a new agent working with an existing agent\n",
    "language_agent = Agent(\n",
    "    name = \"Language Agent\",\n",
    "    instructions = \"You are a language expert. You are given a joke and you need to rewrite it in a different language.\",\n",
    "    model = llm_model\n",
    ")\n",
    "\n",
    "joke_result = await Runner.run(joke_agent, topic)\n",
    "translated_result = await Runner.run(language_agent, f\"Translate this joke to Spanish: {joke_result.final_output}\")\n",
    "\n",
    "print(f\"Original joke:\\n{joke_result.final_output}\\n\")\n",
    "print(f\"Translated joke:\\n{translated_result.final_output}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbfcd02",
   "metadata": {},
   "source": [
    "#### Structured outputs\n",
    "\n",
    "Structured outputs are a way to format the output of an LLM in a structured manner. This can be useful for task that require specific formatting or data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4bb25e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recipe(title='Italian Sausage with Spaghetti', ingredients=['400g (14 oz) spaghetti', '4 Italian sausages (mild or hot, as preferred)', '2 tablespoons olive oil', '1 onion, finely chopped', '3 garlic cloves, minced', '1 can (400g/14 oz) crushed tomatoes', '2 tablespoons tomato paste', '1 teaspoon dried oregano', '1 teaspoon dried basil', '1/2 teaspoon chili flakes (optional)', 'Salt and pepper to taste', 'Parmesan cheese, grated (for serving)', 'Fresh basil leaves (for garnish)'], cooking_time=40, servings=4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Recipe(BaseModel):\n",
    "    title: str\n",
    "    ingredients: list[str]\n",
    "    cooking_time: int # in minutes\n",
    "    servings: int\n",
    "\n",
    "recipe_agent = Agent(\n",
    "    name = \"Recipe Agent\",\n",
    "    instructions = (\"You are an agent for creating recipes. You will be given the name of a food and your job\"\n",
    "                    \" is to output that as an actual detailed recipe. The cooking time should be in minutes.\"),\n",
    "    output_type = Recipe\n",
    ")\n",
    "\n",
    "response = await Runner.run(recipe_agent, \"Italian Sasuage with Spaghetti\")\n",
    "response.final_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oai_agent_sdk_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
